{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "## Step 1\n\n1) Download the dataset.\n\n2) Make a copy of the dataset.\n\n3) Examine the data types and determine if they match the content.\n\n4) Write the conclusion.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Import libraries for working with tables and graphs\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Load the dataset\ndf_raw = pd.read_csv(\"https://code.s3.yandex.net/datasets/credit_scoring_eng.csv\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Copy the dataset for working with it into the df variable or another\ndf = df_raw.copy()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Examine the general information about the dataset\n\ndf.info()\ndf.sample(5)\ndf.describe()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "After reviewing the data, you can draw some quick conclusions. First, there are gaps in the days_employed and total_income columns. It is likely that we are talking about unemployed people or those who have just started working. With a more detailed analysis, we will determine what we will do with them. Secondly, the days_employed column does not have the correct format (negative values). But since we won’t need it for work, we won’t touch it (to save our time). Strange values ​​were also found in the children column (negative and abnormally high), and there may have been an error when entering data in the dob_years column (age cannot be 0). Also, with a more detailed analysis, we will decide whether to delete or replace this data (or maybe just skip it). You will also need to examine abnormally high values ​​in the total_income column. There are also abnormally high values ​​in the days_employed column (401755 days of work experience is 1100 years). But since we won’t need it for work, we won’t touch it (to save our time).",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Step 2: Preprocess the data\n\n1) Find and examine missing values in columns.\n \n2) Fix missing values by removing or replacing them.\n \n3)  Explain the chosen strategy for handling missing values.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Count the volume of data:\nprint('Number of rows in the dataframe:', len(df))\n\n# Count the number of missing values:\nprint('Number of missing values by columns:')\nprint(df.isna().sum())\n\n# Ensure that all those with missing values in days employed also have missing values in monthly income:\ndf_isna = df.query('days_employed.isna() & total_income.isna()')\nprint('Information about rows without employment and income data:')\nprint(df_isna.info())",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Count the number of missing values in the dataset:\ndf_na_counts = df_raw.isna().sum()\n\n# Count the number of rows in the dataset:\ntotal_raws = len(df_raw)\n\n# Calculate the percentage of missing values in the entire dataset:\ndf_na_share = df_na_counts / total_raws * 100\n\n# Output the calculations:\nprint('Percentage of missing values in the column:')\nprint(df_na_share)\n\n# Remove rows with missing values in the days_employed and total_income columns:\ndf.dropna(subset=['days_employed', 'total_income'], inplace=True)\n\n# Check the result:\nprint('Number of missing values by columns:')\nprint(df.isna().sum())\nprint(\"Number of rows after removing missing values:\")\nprint(len(df))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Since if there is a gap in the days_employed column (number of days worked), there is also a gap in the total_income column (monthly income), we can conclude that the gaps were left because the person does not have a job (= no income), or has not worked yet one day (=did not receive salary). Such data (with gaps) is 10%. Replacing them with an average or median value would not be entirely correct, since the purpose of the task is a system for assessing the ability of a potential borrower to repay his loan. And I would like to start from the real values ​​of monthly income. Therefore, the decision was made to remove data with gaps. Given that gaps constitute a significant portion of the data (10%), their removal may affect the size and representativeness of the data, but this is preferable to filling in values ​​that may be unreasonable or misleading.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Step 3\n\n1) Examine the unique values in the education and gender columns.\n2) Eliminate implicit duplicates and incorrect values.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Find all unique values in the education column:\nunique_education = df['education'].unique()\n# Find all unique values in the gender column:\nunique_gender = df['gender'].unique()\n\n# Output all unique values in the education column:\nprint('Unique values in the \"education\" column:')\nprint(unique_education)\n# Output all unique values in the gender column:\nprint('Unique values in the \"gender\" column:')\nprint(unique_gender)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Convert names to lowercase to eliminate implicit duplicates:\ndf['education'] = df['education'].str.lower()\n\n# Check the result:\nprint('Unique values in the \"education\" column after processing:')\nprint(df['education'].unique())\n\n# Analyze 'XNA' values in the gender column:\ndf_gender_xna = df.query('gender == \"XNA\"')\nif not df_gender_xna.empty:\n    print('Number of \"XNA\" values in the \"gender\" column:', len(df_gender_xna))\nelse:\n    print('No \"XNA\" values found in the \"gender\" column.')\n\n# Remove 'XNA' values in the gender column if they are less than 1%:\nif len(df_gender_xna) / len(df) < 0.01:  # If less than 1% of data\n    df = df[df['gender'] != 'XNA']\n    print('Rows with \"XNA\" in \"gender\" have been removed.')\n\n# Check the result:\nprint('Unique values in the \"gender\" column after processing:')\nprint(df['gender'].unique())\n\nprint(\"Number of rows after removing duplicates:\")\nprint(len(df))\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Implicit duplicates have been eliminated in the education column. In the gender column, rows with 'XNA' values ​​have been removed. Since such values ​​turned out to be less than 1%, their removal will not be critical for further analysis.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Step 4\n\n1) Check for duplicates. Examine duplicate data, if any, and decide whether to delete it or leave it.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "duplicate_rows = df.duplicated()\nprint(\"Number of duplicates in the dataframe:\", duplicate_rows.sum())\n\n# No duplicates in the dataframe.\n\n# Find out how much data was removed during preprocessing:\n\n# Find the initial number of rows in the dataset:\ntotal_rows_count = len(df_raw)\n# Find the number of rows in the dataset after preprocessing:\nactual_rows_count = len(df)\n# Calculate:\nshare = 100 - ((actual_rows_count / total_rows_count) * 100)\n# Output:\nprint(f'Total lost in preprocessing: {share:.0f}% of data')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Step 5\n\n1) Examine the columns total_income, dob_age, chidlren for outliers and anomalous values, including using graphs. If outliers or anomalies are detected, make an informed decision about their fate.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Presence of outliers in the total_income column",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Get basic statistical information for the total_income column:\ndf['total_income'].describe(percentiles=[0.5, 0.6, 0.7, 0.8, 0.95, 0.99])",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Get basic statistical information for the total_income column:\ndf['total_income'].describe(percentiles=[0.5, 0.6, 0.7, 0.8, 0.95, 0.99])\n\n# Define the outlier threshold as the 95th percentile of the total_income values:\noutliers = df['total_income'].quantile(0.95)\n\n# Filter the data, keeping only values above the identified outlier threshold:\nnew_df = df[df['total_income'] > outliers]",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Set the size of the box:\nplt.figure(figsize=(10, 6))\n\n# Build a horizontal boxplot:\nplt.boxplot(x=df['total_income'],  # monthly income data\n            vert=False,     # horizontal boxplot\n            showmeans=True, # show mean on the graph\n            meanline=True,  # show mean as a line on the graph\n            patch_artist=True,  # fill boxplot with color\n            # set outliers color to red\n            flierprops=dict(markerfacecolor='red'))\n# Add a title to the chart:\nplt.title(\"Analysis of Monthly Income Outliers\")\n# Add a label to the X axis:\nplt.xlabel(\"Monthly Income\")\nplt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Check people with income over 200000:\ndf_max = df.query('total_income > 200000')\ndf_max",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "It was decided not to make changes as the monthly income of individuals may be high. Moreover, after analyzing people with incomes over 200,000, you can see that most of them are businessmen. Or working people with extensive work experience",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Presence of outliers in the dob_years column",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Get basic statistical information for the dob_years column:\ndf['dob_years'].describe()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Find out how many rows in the dob_years column contain 0:\ndf_0_years = df.query('dob_years == 0')\ndf_0_years\n\n# Since the number of rows with a value of 0 in the dob_years column is small, we decided to replace these values with the mean\n# value in the dob_years column",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Create a variable that will store the mean value of the dob_years column:\nvalue_age_replace = round(df['dob_years'].mean())\n# Perform the replacement\ndf['dob_years'].replace(to_replace=0, value=value_age_replace, inplace=True)\n# Check the basic statistical information for the dob_years column after replacement:\ndf['dob_years'].describe()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "We made sure that the replacement did not entail critical changes in the main statistical indicators in the dob_years column",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Presence of outliers in the children column",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Get basic statistical information for the children column:\ndf['children'].describe()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Examine the rows where the value -1 appears:\ndf_outliers_negative = df.query('children == -1')\n# Output the number of these rows:\nprint('Number of rows where \"children\" is -1:', len(df_outliers_negative))\n\n# Most likely, this is a data entry error where -1 was intended to be 1 child. Therefore, in the next step\n# we will make the replacement.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Replace -1 in the children column with 1:\ndf['children'].replace(to_replace=-1, value=1, inplace=True)\nprint('Unique values in the \"children\" column:', df['children'].unique())",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Examine the rows where the value 20 appears in the children column:\ndf_outliers_max = df.query('children == 20')\n# Output the number of these rows:\nprint('Number of rows where \"children\" is 20:', len(df_outliers_max))\n\n# Most likely, this is a data entry error where the value 20 should have been entered as 2.\n# Therefore, in the next step, we will make the replacement.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Replace 20 in the children column with 2:\ndf['children'].replace(to_replace=20, value=2, inplace=True)\nprint('Unique values in the \"children\" column:', df['children'].unique())",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Step 6\n\n1) Divide clients into 5 categories based on income level:\n\n No income - people without work and with zero income.\n \n Very low income - people earning below the 14th percentile of the overall income distribution.\n \n Low income - people earning between the 14th and 34th percentiles of the overall income distribution.\n \n Middle income—people earning between the 34th and 78th percentiles of the overall income distribution.\n \n High income - people earning more than the 78th percentile of the total income distribution.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Divide the data into 4 categories using percentiles:\ndf['category_qcat'] = pd.qcut(df['total_income'], q=[0, 0.14, 0.34, 0.78, 1],\n                              labels=cat_names)\nprint(df['category_qcat'].value_counts()) \n\n# The division was made into 4 categories because during preprocessing\n# the rows with a value of 0 in the total_income column (monthly income) were removed. Therefore, only clients with incomes remain.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Divide clients into two age categories: under 40 and after. Save the result in the age_category column.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def age(dob_years):\n    \n    # Define a conditional construct to check the value of dob_years:\n\n    # If the client is up to 40 years old:\n    if dob_years <= 40:\n        return 'Up to 40 years'\n    \n    # If the client is older than 40 years:\n    elif dob_years > 40:\n        return 'Older than 40 years'\n    \n# Create a new column with age categorization:\ndf['age_category'] = df['dob_years'].apply(age)\n\n# Display the first 10 rows on the screen:\nprint(df[['dob_years', 'age_category']].head(10)) ",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Divide clients into several categories based on the number of children: no children, from one to two, from three or more. Save the result in the childrens_category column.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def children_count(children):\n    \n    # Define a conditional construct to check the value of children:\n\n    # If there are no children:\n    if children < 1:\n        return 'No children'\n    \n    # If there are 1 or 2 children:\n    elif 1 <= children <= 2:\n        return '1 to 2 children'\n    \n    # If there are more than 3 children:\n    elif children >= 3:\n        return '3 or more children'\n    \n# Create a new column with categorization by number of children:\ndf['childrens_category'] = df['children'].apply(children_count)\n\n# Display the first 10 rows on the screen:\nprint(df[['children', 'childrens_category']].head(10))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Step 7\n\n1) Conduct exploratory data analysis\n\nSet the structure of the most voluminous part of the study. Explore factors: Income level, Education, Age, Number of children. Is the distribution different between debtors and non-debtors? Explore the question graphically. Build a summary table for each factor and show how often debtors occur in each group of clients. Select the appropriate visualization and compare the 2 groups.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Income study",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Create a pivot table to study the relationship between income level and whether the client was a debtor:\ndf_pivot = df.pivot_table(index='category_qcat', columns='debt', values='total_income', aggfunc='count')\n\n# Calculate the total number of clients in each category:\ndf_pivot['total'] = df_pivot.sum(axis=1)\n\n# Calculate the percentage of clients without debt:\ndf_pivot['no_debt_percentage'] = (df_pivot[1] / df_pivot['total']) * 100\n\n# Convert the pivot table to a long format for use with seaborn:\ndf_pivot_long = df_pivot.reset_index()\ndf_pivot_long = df_pivot_long[['category_qcat', 'no_debt_percentage']]\n\n# Plotting the graph using seaborn:\nplt.figure(figsize=(10, 6))\nax = sns.barplot(x='category_qcat', y='no_debt_percentage', data=df_pivot_long)\nplt.title(\"Share of Debtors by Income Categories\")\nplt.xlabel(\"Income Category\")\nplt.ylabel(\"%\")\nplt.xticks(rotation=45)\n\n# Add percentage values above each bar:\nfor p in ax.patches:\n    ax.annotate(f'{p.get_height():.1f}%', (p.get_x() + p.get_width() / 2., p.get_height()),\n                ha='center', va='center', fontsize=12, color='black', xytext=(0, 5),\n                textcoords='offset points')\nplt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "From the graph we see that most often there are debtors with Low and Medium incomes. But the difference with the other two groups is not so big that we can draw any conclusions on this basis.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Study of dependence on educational level",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Create a function to categorize clients based on their education level:\ndef education_group (education):\n    \n    # Define a conditional structure to check the value of education\n\n    # If bachelor's degree:\n    if education == \"bachelor's degree\":\n        return 'Higher Education - Bachelor’s Degree'\n    \n    # If secondary education:\n    elif education == \"secondary education\":\n        return 'Secondary Education'\n    \n    # If some college:\n    elif education == \"some college\":\n        return 'Vocational Education'\n    \n    # If primary education:\n    elif education == \"primary education\":\n        return 'Primary Education'\n    \n    # If graduate degree (master's or doctorate):\n    elif education == \"graduate degree\":\n        return 'Doctorate or Master’s Degree'\n    \n# Create a new column with categorization by education level:\ndf['education_level'] = df['education'].apply(education_group)\n\n# Create a pivot table to study the relationship between education level and whether the client has been a debtor:\ndf_pivot = df.pivot_table(index='education_level', columns='debt',\n                          values='total_income', aggfunc='count').sort_values(by='education_level')\n\n# Calculate the total number of clients in each category:\ndf_pivot['total'] = df_pivot.sum(axis=1)\n\n# Calculate the percentage of clients who are debtors:\ndf_pivot['no_debt_percentage'] = (df_pivot[1] / df_pivot['total']) * 100\n\n# Convert the pivot table to long format for use with seaborn:\ndf_pivot_long = df_pivot.reset_index()\ndf_pivot_long = df_pivot_long[['education_level', 'no_debt_percentage']]\n\n# Plot the graph using seaborn:\nplt.figure(figsize=(10, 6))\nax = sns.barplot(x='education_level', y='no_debt_percentage', data=df_pivot_long)\nplt.title(\"Percentage of Debtor Clients (Grouped by Education Level)\")\nplt.xlabel(\"Education Level Category\")\nplt.ylabel(\"%\")\nplt.xticks(rotation=45)  \n\n# Add percentage values above each bar:\nfor p in ax.patches:\n    ax.annotate(f'{p.get_height():.1f}%', (p.get_x() + p.get_width() / 2., p.get_height()),\n                ha='center', va='center', fontsize=12, color='black', xytext=(0, 5),\n                textcoords='offset points')\nplt.show()\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "This graph is more visual. Here we can conclude that debtors are significantly less common among people with higher education. the largest number of debtors is in the group of people with primary education.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Study of dependence on age category",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Creating a pivot table to study the dependency on age and whether the client was a debtor:\n\ndf_pivot = df.pivot_table(index='age_category', columns='debt',\nvalues='total_income', aggfunc='count')\n# Calculating the total number of clients in each category:\n\ndf_pivot['total'] = df_pivot.sum(axis=1)\n# Calculating the percentage of debtor clients:\n\ndf_pivot['no_debt_percentage'] = (df_pivot[1] / df_pivot['total']) * 100\n# Converting the pivot table to long format for use with seaborn:\n\ndf_pivot_long = df_pivot.reset_index()\ndf_pivot_long = df_pivot_long[['age_category', 'no_debt_percentage']]\n# Plotting the graph using seaborn:\n\nplt.figure(figsize=(10, 6))\nax = sns.barplot(x='age_category', y='no_debt_percentage', data=df_pivot_long)\nplt.title(\"Percentage of debtor clients (grouped by age)\")\nplt.xlabel(\"Age Category\")\nplt.ylabel(\"%\")\nplt.xticks(rotation=45)\n# Adding percentage values above each column:\n\nfor p in ax.patches:\n    ax.annotate(f'{p.get_height():.1f}%', (p.get_x() + p.get_width() / 2., p.get_height()),\n                ha='center', va='center', fontsize=12, color='black', xytext=(0, 5),\n                textcoords='offset points')\nplt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "This graph also makes it quite clear that among clients in the age category under 40 years old one can more often meet a debtor.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Study of dependence on the number of children",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Creating a pivot table to study the dependency on the number of children and whether the client was a debtor:\n\ndf_pivot = df.pivot_table(index='childrens_category', columns='debt',\nvalues='total_income', aggfunc='count')\n# Calculating the total number of clients in each category:\n\ndf_pivot['total'] = df_pivot.sum(axis=1)\n# Calculating the percentage of debtor clients:\n\ndf_pivot['no_debt_percentage'] = (df_pivot[1] / df_pivot['total']) * 100\n# Converting the pivot table to long format for use with seaborn:\n\ndf_pivot_long = df_pivot.reset_index()\ndf_pivot_long = df_pivot_long[['childrens_category', 'no_debt_percentage']]\n# Plotting the graph using seaborn:\n\nplt.figure(figsize=(10, 6))\nax = sns.barplot(x='childrens_category', y='no_debt_percentage', data=df_pivot_long)\nplt.title(\"Percentage of debtor clients (grouped by number of children)\")\nplt.xlabel(\"Number of Children\")\nplt.ylabel(\"%\")\nplt.xticks(rotation=45)\n# Adding percentage values above each column:\n\nfor p in ax.patches:\n    ax.annotate(f'{p.get_height():.1f}%', (p.get_x() + p.get_width() / 2., p.get_height()),\n                ha='center', va='center', fontsize=12, color='black', xytext=(0, 5),\n                textcoords='offset points')\nplt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Most often there are debtors who have from 1 to 2 children. But the difference with the other 2 groups is not critical.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Test the research hypothesis: Customers with children have a higher level of financial responsibility and therefore a lower risk of loan delinquency.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Creating a pivot table:\n\ndf_pivot = df.pivot_table(index='childrens_category', columns='debt',\nvalues='total_income', aggfunc='count')\n# Calculating the total number of clients in each category:\n\ndf_pivot['total'] = df_pivot.sum(axis=1)\n# Calculating the percentage of clients without debts:\n\ndf_pivot['no_debt_percentage'] = (df_pivot[0] / df_pivot['total']) * 100\n# Converting the pivot table to long format for use with seaborn:\n\ndf_pivot_long = df_pivot.reset_index()\ndf_pivot_long = df_pivot_long[['childrens_category', 'no_debt_percentage']]\n# Plotting the graph:\n\nplt.figure(figsize=(10, 6))\nax = sns.barplot(x='childrens_category', y='no_debt_percentage', data=df_pivot_long)\nplt.title(\"Percentage of clients without debts (grouped by number of children)\")\nplt.xlabel(\"Number of Children\")\nplt.ylabel('%')\nplt.xticks(rotation=45)\n# Adding percentage values above each column:\n\nfor p in ax.patches:\n    ax.annotate(f'{p.get_height():.1f}%', (p.get_x() + p.get_width() / 2., p.get_height()),\n                ha='center', va='center', fontsize=10, color='black', xytext=(0, 5),\n                textcoords='offset points')\nplt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "This hypothesis cannot be confirmed. The number of children does not affect the level of financial responsibility.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Test the research hypothesis: Low-income single men are more likely to be in debt than middle-income married men.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Creating a function to categorize clients into two categories:\ndef men_group(row):\n    \n    family_status = row['family_status']\n    category_qcat = row['category_qcat'] \n    gender = row['gender']\n    \n    \n    if (family_status in [\"married\", \"civil partnership\"]) and (category_qcat == \"Средний доход\") and (gender == \"M\"):\n        return 'Семейные мужчины со средним доходом'\n    \n    if (family_status in [\"unmarried\", \"widow / widower\", \"divorced\"]) and (category_qcat == \"Низкий доход\") and (gender == \"M\"):\n        return 'Одинокие мужчины с маленьким доходом'\n    \n    return None  # Returning None if no condition is met\n\n# Creating a new column with categorization by marital status and income:\ndf['men_category'] = df.apply(men_group, axis=1) \n\n# Creating a pivot table:\ndf_pivot = df.pivot_table(index='men_category', columns='debt',\n                          values='total_income', aggfunc='count')\n\n# Calculating the total number of clients in each category:\ndf_pivot['total'] = df_pivot.sum(axis=1)\n\n# Calculating the percentage of debtor clients:\ndf_pivot['no_debt_percentage'] = (df_pivot[1] / df_pivot['total']) * 100\n\n# Converting the pivot table to long format for use with seaborn:\ndf_pivot_long = df_pivot.reset_index()\ndf_pivot_long = df_pivot_long[['men_category', 'no_debt_percentage']]\n\n# Plotting the graph using seaborn:\nplt.figure(figsize=(10, 6))\nax = sns.barplot(x='men_category', y='no_debt_percentage', data=df_pivot_long)\nplt.title(\"Percentage of debtor clients\")\nplt.xlabel(\"Category\")\nplt.ylabel(\"%\")\nplt.xticks(rotation=45)  \n\n# Adding percentage values above each column:\nfor p in ax.patches:\n    ax.annotate(f'{p.get_height():.1f}%', (p.get_x() + p.get_width() / 2., p.get_height()),\n                ha='center', va='center', fontsize=10, color='black', xytext=(0, 5),\n                textcoords='offset points')\nplt.show()\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "This hypothesis can be confirmed. Single men with low incomes actually become debtors more often.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Step 8\n\nResearch the reasons for taking out a loan. Is it true that people who took out student loans were least likely to become debtors?",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Explore unique values in the 'purpose' field\ndf['purpose'].unique()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Split clients into 2 groups\ndef find_education_purpose(purpose): \n    # List of education-related purposes:\n    education_keywords = [\n        \"supplementary education\", \"education\", \"to become educated\", \"getting an education\",\n        \"to get a supplementary education\", \"getting higher education\",\n        \"profile education\", \"university education\", \"going to university\"\n    ]\n    \n    # Check if the purpose is in the list of education-related purposes:\n    if purpose in education_keywords:\n        return \"Education\"\n    else:\n        return \"Other\"\n\n# Create a new column with the purpose of the loan:\ndf['purpose_category'] = df['purpose'].apply(find_education_purpose)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Investigate the obtained groups by the proportion of clients who defaulted\n# Create a pivot table:\ndf_pivot = df.pivot_table(index='purpose_category', columns='debt',\n                          values='total_income', aggfunc='count')\n\n# Calculate the total number of clients in each category:\ndf_pivot['total'] = df_pivot.sum(axis=1)\n\n# Calculate the percentage of debtor clients:\ndf_pivot['no_debt_percentage'] = (df_pivot[1] / df_pivot['total']) * 100\n\n# Convert the pivot table to long format for use with seaborn:\ndf_pivot_long = df_pivot.reset_index()\ndf_pivot_long = df_pivot_long[['purpose_category', 'no_debt_percentage']]\n\n# Plot the graph using seaborn:\nplt.figure(figsize=(10, 6))\nax = sns.barplot(x='purpose_category', y='no_debt_percentage', data=df_pivot_long)\nplt.title(\"Percentage of debtor clients\")\nplt.xlabel(\"Loan Purpose\")\nplt.ylabel(\"%\")\nplt.xticks(rotation=45)  \n\n# Add percentage values above each column:\nfor p in ax.patches:\n    ax.annotate(f'{p.get_height():.1f}%', (p.get_x() + p.get_width() / 2., p.get_height()),\n                ha='center', va='center', fontsize=10, color='black', xytext=(0, 5),\n                textcoords='offset points')\nplt.show()\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "This hypothesis is not true. Among people who took out a loan for the purpose of obtaining an education, you are more likely to find debtors than among people with other loan purposes.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}